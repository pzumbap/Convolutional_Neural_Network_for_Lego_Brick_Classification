{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network for Lego Brick Classification\n",
    "## Image Recognition Model for Differentiating Types of Lego Bricks\n",
    "### Pablo X Zumba"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set for this exercise contains rendered images of 16 different types of Lego bricks. This is an image classification task: build a model that can correctly identify lego bricks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal\n",
    "\n",
    "Use the **train** folder for Lego images and build a model to predict the **category** of each image. Then, validate the model on the images in the **valid** folder with different images. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-03 17:45:19.019861: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, DirectoryIterator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6379 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "#Image Data Generator manipulates and \"augments\" images\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "\n",
    "# Directory Iterator reads images from a directory\n",
    "\n",
    "train_data = DirectoryIterator(\n",
    "    directory=\"LEGO/train\",\n",
    "    image_data_generator = train_datagen,\n",
    "    target_size=(32, 32),                    ###### ENTER values for XXX ########\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=100,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1555 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "valid_data = DirectoryIterator(\n",
    "    directory=\"LEGO/valid\",\n",
    "    image_data_generator = valid_datagen,\n",
    "    target_size=(32, 32),                     ###### ENTER values for XXX ########\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=100,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build your model \n",
    "\n",
    "**Be careful with the output layer: number of neurons must match the number of categories to predict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 16)        448       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 16)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 16, 16, 16)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 14, 14, 32)        4640      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 7, 7, 32)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 7, 7, 32)          0         \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-03 17:45:33.808215: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " flatten (Flatten)           (None, 1568)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               200832    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                2064      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 207,984\n",
      "Trainable params: 207,984\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=(3, 3), padding='same', activation='relu', \n",
    "                 input_shape=(32,32,3)))\n",
    "\n",
    "#model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "#model.add(Conv2D(filters=32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "model.add(Dense(16, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# initiate adam optimizer\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "64/64 [==============================] - 14s 208ms/step - loss: 1.6360 - accuracy: 0.4193 - val_loss: 0.8430 - val_accuracy: 0.6701\n",
      "Epoch 2/5\n",
      "64/64 [==============================] - 11s 173ms/step - loss: 1.0207 - accuracy: 0.6004 - val_loss: 0.6185 - val_accuracy: 0.7640\n",
      "Epoch 3/5\n",
      "64/64 [==============================] - 10s 163ms/step - loss: 0.8546 - accuracy: 0.6581 - val_loss: 0.5156 - val_accuracy: 0.8019\n",
      "Epoch 4/5\n",
      "64/64 [==============================] - 11s 165ms/step - loss: 0.7855 - accuracy: 0.7000 - val_loss: 0.4790 - val_accuracy: 0.8302\n",
      "Epoch 5/5\n",
      "64/64 [==============================] - 11s 166ms/step - loss: 0.7421 - accuracy: 0.7101 - val_loss: 0.4608 - val_accuracy: 0.8424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9c98eb2820>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "        train_data,\n",
    "        epochs=5,\n",
    "        validation_data=valid_data,\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lego images are 200x200 pixels; they are by nature more complex in terms of shape than the images of the previous fruits. Therefore, a larger input target size was and will be needed to get a better accuracy performance. This will lead to a larger payload on the CPU/GPU."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f9c9bb7c370>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "img = load_img(\"LEGO/valid/3040 Roof Tile 1x2x45deg/201706162106-0019.png\",\n",
    "               color_mode='rgb',\n",
    "               target_size=(32,32)\n",
    "              )\n",
    "\n",
    "\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 139ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[7.9132128e-08, 8.9622965e-08, 2.4383884e-02, 1.3526691e-03,\n",
       "        5.9248275e-01, 1.4114248e-06, 1.4302272e-01, 5.5806645e-06,\n",
       "        7.9589711e-08, 2.3871271e-01, 8.5317133e-06, 5.9551156e-11,\n",
       "        2.9016839e-10, 5.4771204e-10, 4.4006965e-06, 2.5133082e-05]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert the image to array\n",
    "single_image = img_to_array(img)\n",
    "\n",
    "#Also divide the image values by 255 to normalize\n",
    "img_rank4 = np.expand_dims(single_image/255, axis=0)\n",
    "\n",
    "model.predict(img_rank4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.  , 0.  , 0.02, 0.  , 0.59, 0.  , 0.14, 0.  , 0.  , 0.24, 0.  ,\n",
       "        0.  , 0.  , 0.  , 0.  , 0.  ]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(model.predict(img_rank4),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can predict the class directly using the following function:\n",
    "\n",
    "np.argmax(model.predict(img_rank4), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'11214 Bush 3M friction with Cross axle': 0,\n",
       " '18651 Cross Axle 2M with Snap friction': 1,\n",
       " '2357 Brick corner 1x2x2': 2,\n",
       " '3003 Brick 2x2': 3,\n",
       " '3004 Brick 1x2': 4,\n",
       " '3005 Brick 1x1': 5,\n",
       " '3022 Plate 2x2': 6,\n",
       " '3023 Plate 1x2': 7,\n",
       " '3024 Plate 1x1': 8,\n",
       " '3040 Roof Tile 1x2x45deg': 9,\n",
       " '3069 Flat Tile 1x2': 10,\n",
       " '32123 half Bush': 11,\n",
       " '3673 Peg 2M': 12,\n",
       " '3713 Bush for Cross Axle': 13,\n",
       " '3794 Plate 1X2 with 1 Knob': 14,\n",
       " '6632 Technic Lever 3M': 15}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can retrieve the class labels from the train_generator:\n",
    "\n",
    "label_map = (train_data.class_indices)\n",
    "\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3004 Brick 1x2'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can retrieve the class label of the prediction:\n",
    "\n",
    "list(label_map.keys())[np.argmax(model.predict(img_rank4), axis=-1)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "6e8d503ca3497b2311276643aea34fa4462df8f5c0c9e65d3521006dbd5b3aa2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
